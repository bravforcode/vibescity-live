#!/usr/bin/env python3
"""
Data Pipeline - Import Thailand venue data into Supabase
Transforms OSM data and handles upserts to avoid duplicates
Designed for cloud deployment with GitHub Actions
"""
import json
import os
from datetime import UTC, datetime
from pathlib import Path

# Try to import supabase, handle gracefully if not available
try:
    from supabase import Client, create_client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âš ï¸ Supabase not installed. Run: pip install supabase")

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

SUPABASE_URL = os.getenv("SUPABASE_URL", "")
SUPABASE_KEY = os.getenv("SUPABASE_KEY", "")

# Category color mapping for UI
CATEGORY_COLORS = {
    "à¸šà¸²à¸£à¹Œ": "#ef4444",
    "à¸œà¸±à¸š": "#a855f7",
    "à¹„à¸™à¸—à¹Œà¸„à¸¥à¸±à¸š": "#ec4899",
    "à¸£à¹‰à¸²à¸™à¸­à¸²à¸«à¸²à¸£": "#22c55e",
    "à¸„à¸²à¹€à¸Ÿà¹ˆ": "#f59e0b",
    "à¸Ÿà¸²à¸ªà¸•à¹Œà¸Ÿà¸¹à¹‰à¸”": "#f97316",
    "à¸„à¸²à¸£à¸²à¹‚à¸­à¹€à¸à¸°": "#8b5cf6",
    "à¹‚à¸£à¸‡à¸«à¸™à¸±à¸‡": "#3b82f6",
    "à¹‚à¸£à¸‡à¸¥à¸°à¸„à¸£": "#6366f1",
    "à¸ªà¸›à¸²": "#14b8a6",
    "à¸™à¸§à¸”": "#06b6d4",
    "à¹‚à¸£à¸‡à¹à¸£à¸¡": "#0ea5e9",
    "à¹‚à¸®à¸ªà¹€à¸—à¸¥": "#0284c7",
    "à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸—à¹ˆà¸­à¸‡à¹€à¸—à¸µà¹ˆà¸¢à¸§": "#10b981",
    "à¸à¸´à¸à¸´à¸˜à¸ à¸±à¸“à¸‘à¹Œ": "#84cc16",
    "à¸«à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸à¸ªà¸´à¸™à¸„à¹‰à¸²": "#eab308",
    "à¸ªà¸§à¸™à¸ªà¸²à¸˜à¸²à¸£à¸“à¸°": "#22c55e",
    "à¸Ÿà¸´à¸•à¹€à¸™à¸ª": "#f43f5e",
}


def transform_venue(osm_venue: dict) -> dict:
    """Transform OSM venue to Supabase venues table format"""
    category = osm_venue.get("category", "à¸­à¸·à¹ˆà¸™à¹†")

    # Build social links object
    social_links = {}
    if osm_venue.get("facebook"):
        social_links["facebook"] = osm_venue["facebook"]
    if osm_venue.get("instagram"):
        social_links["instagram"] = osm_venue["instagram"]
    if osm_venue.get("tiktok"):
        social_links["tiktok"] = osm_venue["tiktok"]
    if osm_venue.get("website"):
        social_links["website"] = osm_venue["website"]

    return {
        "name": osm_venue.get("name", ""),
        "name_en": osm_venue.get("name_en", ""),
        "category": category,
        "latitude": osm_venue.get("latitude"),
        "longitude": osm_venue.get("longitude"),
        "province": osm_venue.get("province", ""),
        "region": osm_venue.get("region", ""),
        "district": osm_venue.get("address", ""),
        "status": "OFF",  # Default, will be updated by real-time system
        "category_color": CATEGORY_COLORS.get(category, "#6b7280"),
        "social_links": social_links if social_links else None,
        "image_urls": [],
        "phone": osm_venue.get("phone"),
        "opening_hours": osm_venue.get("opening_hours"),
        "verified": False,
        "is_promoted": False,
        "source": "osm",
        "osm_id": osm_venue.get("osm_id", ""),
        "osm_type": osm_venue.get("osm_type", "node"),
        "updated_at": datetime.now(UTC).isoformat(),
    }


def load_venue_data(filename: str = "thailand_venues.json") -> list[dict]:
    """Load scraped venue data from JSON file"""
    file_path = Path(__file__).parent / filename

    if not file_path.exists():
        print(f"âŒ File not found: {file_path}")
        print("   Run osm_scraper.py first!")
        return []

    with open(file_path, encoding="utf-8") as f:
        data = json.load(f)

    return data.get("venues", [])


def import_to_supabase(venues: list[dict], batch_size: int = 50):
    """Import venues to Supabase with upsert (insert or update)"""
    if not SUPABASE_AVAILABLE:
        print("âŒ Supabase library not available")
        return

    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ SUPABASE_URL and SUPABASE_KEY environment variables required")
        print("   Set them in .env or as environment variables")
        return

    print("ğŸ”Œ Connecting to Supabase...")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

    # Transform all venues
    print(f"ğŸ”„ Transforming {len(venues)} venues...")
    transformed = [transform_venue(v) for v in venues if v.get("name")]

    # Filter out invalid entries
    valid_venues = [v for v in transformed if v.get("latitude") and v.get("longitude")]
    print(f"âœ… {len(valid_venues)} valid venues to import")

    # Batch upsert
    success_count = 0
    error_count = 0
    total_batches = (len(valid_venues) + batch_size - 1) // batch_size

    print(f"ğŸ“¤ Importing in {total_batches} batches...")

    for i in range(0, len(valid_venues), batch_size):
        batch = valid_venues[i:i + batch_size]
        batch_num = i // batch_size + 1

        try:
            # Upsert based on osm_id to avoid duplicates
            supabase.table("venues").upsert(
                batch,
                on_conflict="osm_id"
            ).execute()

            success_count += len(batch)
            print(f"   âœ… Batch {batch_num}/{total_batches}: {len(batch)} venues")

        except Exception as e:
            error_count += len(batch)
            error_msg = str(e)[:100]
            print(f"   âŒ Batch {batch_num}/{total_batches}: Error - {error_msg}")

    print()
    print("=" * 50)
    print("ğŸ“Š Import Summary:")
    print(f"   âœ… Success: {success_count}")
    print(f"   âŒ Errors: {error_count}")
    print(f"   ğŸ“ Total processed: {success_count + error_count}")


def generate_stats(venues: list[dict]) -> dict:
    """Generate statistics from venue data"""
    stats = {
        "total": len(venues),
        "by_province": {},
        "by_category": {},
        "by_region": {},
    }

    for v in venues:
        province = v.get("province", "Unknown")
        category = v.get("category", "Other")
        region = v.get("region", "unknown")

        stats["by_province"][province] = stats["by_province"].get(province, 0) + 1
        stats["by_category"][category] = stats["by_category"].get(category, 0) + 1
        stats["by_region"][region] = stats["by_region"].get(region, 0) + 1

    return stats


def main():
    """Main pipeline function"""
    print("ğŸš€ OSM â†’ Supabase Data Pipeline")
    print("=" * 50)

    # Load data
    venues = load_venue_data()
    if not venues:
        print("No data to import. Exiting.")
        return

    print(f"ğŸ“‚ Loaded {len(venues)} venues from OSM data")

    # Generate and print stats
    stats = generate_stats(venues)
    print("\nğŸ“Š Data Statistics:")
    print(f"   Total venues: {stats['total']}")
    print(f"   Provinces: {len(stats['by_province'])}")
    print(f"   Categories: {len(stats['by_category'])}")

    print("\nğŸ“ Top 10 Provinces:")
    top_provinces = sorted(stats["by_province"].items(), key=lambda x: -x[1])[:10]
    for province, count in top_provinces:
        print(f"   {province}: {count}")

    print("\nğŸ·ï¸  Top 10 Categories:")
    top_categories = sorted(stats["by_category"].items(), key=lambda x: -x[1])[:10]
    for cat, count in top_categories:
        print(f"   {cat}: {count}")

    # Import to Supabase
    print("\n" + "=" * 50)
    import_to_supabase(venues)


if __name__ == "__main__":
    main()
